{"nbformat_minor": 1, "cells": [{"source": "import keras\nfrom keras.datasets import mnist\nimport pickle, numpy\nfrom sklearn.model_selection import train_test_split", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 3}, {"source": "## Load the data from Keras dataset<br>\nReturns two tuples:<br>\nX, X_test: uint8 array of RGB image data with shape (num_samples, 3, 32, 32).<br>\ny, y_test: uint8 array of category labels (integers in range 0-9) with shape (num_samples,).", "cell_type": "markdown", "metadata": {}}, {"source": "# the data, split between train and test sets\n(X,y), (X_test, y_test) = mnist.load_data()", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 4}, {"source": "# split training set into training and validation sets:\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 5}, {"source": "## Write data to project filesystem", "cell_type": "markdown", "metadata": {}}, {"source": "with open('mnist-tf-train.pkl', 'wb') as f:\n    pickle.dump((X_train, y_train), f, protocol=pickle.HIGHEST_PROTOCOL)\n\nwith open('mnist-tf-valid.pkl', 'wb') as f:\n    pickle.dump((X_valid, y_valid), f, protocol=pickle.HIGHEST_PROTOCOL)\n\nwith open('mnist-tf-test.pkl', 'wb') as f:\n    pickle.dump((X_test, y_test), f, protocol=pickle.HIGHEST_PROTOCOL)", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 6}, {"source": "import ibm_boto3\nfrom ibm_botocore.client import Config", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 7}, {"source": "## Insert Cloud Object Storage credentials \n\n1. Select the Data icon (upper right, icon with 1 and 0s)\n2. Select Connections\n3. Select the cell below and then select <b>Insert to code</b> for <b>Connection to project COS</b> to insert credentials\n4. Rename the credentials (which are usually called credentials_1) to cos_credentials.   YOU WILL GET ERRORS IF YOU DO NOT DO THIS!", "cell_type": "markdown", "metadata": {}}, {"source": "\n# @hidden_cell\ncredentials_1 = {\n  'secret_key':'0e0600e5f6bb917f56f6f83b3e269efb17879e785a52e375',\n  'iam_url':'https://iam.ng.bluemix.net/oidc/token',\n  'api_key':'g13BP95BY-k0ZAr_5mDUxETkQsj0Xg68NiIDw6fLx_hH',\n  'resource_instance_id':'crn:v1:bluemix:public:cloud-object-storage:global:a/affc9aad9ed36815e657b2cc4d2616bd:60e98ac9-8749-4d82-b544-b6fcb4933c7f::',\n  'access_key':'6c3128b29392463bb549904b8ed7484c',\n  'url':'https://s3-api.us-geo.objectstorage.service.networklayer.com'\n}\n", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 8}, {"source": "service_endpoint = credentials_1['url']  ", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 10}, {"source": "auth_endpoint = credentials_1['iam_url']  ", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 11}, {"source": "cos = ibm_boto3.client('s3',\n                      ibm_api_key_id=credentials_1['api_key'],\n                      ibm_service_instance_id=credentials_1['resource_instance_id'],\n                      ibm_auth_endpoint=auth_endpoint,\n                      config=Config(signature_version='oauth'),\n                      endpoint_url=service_endpoint)", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 13}, {"source": "## Create bucket name -- I usually append my name to the end (i.e. cifar10-tutorials-joel)", "cell_type": "markdown", "metadata": {}}, {"source": "bucket = \"mnist-demo\"", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 14}, {"source": "## This call may fail if bucket has already been created -- that's fine, simply continue executing the next cells", "cell_type": "markdown", "metadata": {}}, {"source": "files = ['mnist-tf-train.pkl',\n         'mnist-tf-valid.pkl',\n         'mnist-tf-test.pkl']", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 15}, {"source": "for file in files:\n    print('Uploading data {}...', format(file))\n    cos.upload_file(Filename=file, Bucket=bucket, Key=file)", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "Uploading data {}... mnist-tf-train.pkl\nUploading data {}... mnist-tf-valid.pkl\nUploading data {}... mnist-tf-test.pkl\n"}], "execution_count": 16}], "metadata": {"kernelspec": {"display_name": "Python 3.5", "name": "python3", "language": "python"}, "language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "version": "3.5.4", "name": "python", "pygments_lexer": "ipython3", "file_extension": ".py", "codemirror_mode": {"version": 3, "name": "ipython"}}}, "nbformat": 4}